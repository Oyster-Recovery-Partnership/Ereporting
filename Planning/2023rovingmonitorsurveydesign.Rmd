---
title: "2023 Roving Monitor Survey Design Guidance"
author: "Kaycee Coleman"
date: '2022-03-16'
output: pdf_document
urlcolor: blue
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This document utilizes our past efforts to guide 2023 monitoring efforts for all fisheries. If you need to edit or update this report and are unsure on how to use markdown syntax, please see a cheat sheet [here](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf).

```{r, include=FALSE}
#-----------#
# load packages
#-----------#
library(dplyr)
library(ggplot2)
library(readr)
library(lubridate)
library(readxl)
library(hms)
library(stringr)
library(raster)
library(viridis) 
#-----------#

#-----------#
# load data
#-----------#
dir.in = "Library/CloudStorage/OneDrive-SharedLibraries-OysterRecoveryPartnership,Inc/ORP - Operations/Sustainable Fisheries/E-Reporting/Data/FACTSdata/rawdata/" # if not synced and have to download all of the data, change dir. here

# WATERMEN REPORTS
#charter data from 2021
FH = read_csv(paste(dir.in, "CharterTrips_021522.csv", sep=""))
FH$type = "charter"
# shellfish data from 2021-2022
SF21 = read_csv(paste(dir.in, "ShellfishTrips2021only_031622.csv", sep=""))
SF22 = read_csv(paste(dir.in, "ShellfishTrips2022only_031622.csv", sep=""))
SF = rbind(SF21, SF22)
SF$type = "shellfish"
# finfish data from 2019
FF_BC = read_excel(paste(dir.in, "Aug2019_RM_WM.xlsx", sep=""), sheet = 2)
FF_BC$type = FF_BC$Fishery
# trip summary of 2019 - 2020 data all fisheries
trip_sum = read_csv(paste(dir.in, "FACTSMD-851.csv", sep="")) 

# ROVING MONITOR REPORTS
# RM charter data from 2021
RM_FH = read_csv(paste(dir.in, "CharterMonitorReports_021522.csv", sep=""))
RM_FH$type = "charter"
# RM shellfish data from 2021-2022
RM_SF21 = read_csv(paste(dir.in, "ShellfishMonitorReports2021only_031622.csv", sep=""))
RM_SF22 = read_csv(paste(dir.in, "ShellfishMonitorReports2022only_031622.csv", sep=""))
RM_SF = rbind(RM_SF21, RM_SF22)
RM_SF$type = "shellfish"
# RM finfish + blue crab data from 2019
RM_FF_BC = read_excel(paste(dir.in, "Aug2019_RM_WM.xlsx", sep=""), sheet = 1)
RM_FF_BC = left_join(RM_FF_BC, dplyr::select(FF_BC, type, Date, 'Trip ID'), by="Trip ID")

rm(RM_SF21,RM_SF22,SF21,SF22)
#-----------#

#-----------#
# format data
#-----------#
# fix names
names(FH) = gsub(" ","",names(FH))
names(FF_BC) = gsub(" ","",names(FF_BC))
names(SF) = gsub(" ","",names(SF))
names(FH) = gsub("#","",names(FH))
names(FF_BC) = gsub("#","",names(FF_BC))
names(SF) = gsub("#","",names(SF))
names(RM_FH) = gsub(" ","",names(RM_FH))
names(RM_FF_BC) = gsub(" ","",names(RM_FF_BC))
names(RM_SF) = gsub(" ","",names(RM_SF))
names(RM_FH) = gsub("#","",names(RM_FH))
names(RM_FF_BC) = gsub("#","",names(RM_FF_BC))
names(RM_SF) = gsub("#","",names(RM_SF))

# select only what is needed to speed up the join
SF = dplyr::select(SF, TripID, type, Date, SH, EH, EHLandingTime, EHZIP,Gear) %>%
  rename(EHZip = EHZIP)
FH = dplyr::select(FH, TripID, type, Date, SH, EH, EHLandingTime, EHZip,Gear)
FF_BC = dplyr::select(FF_BC, TripID, type, Date, SH, EH, EHLandingTime, EHZip,Gear) %>% 
  mutate(EHLandingTime = as_hms(sapply(strsplit(as.character(EHLandingTime)," "), tail,1))) 

RM_SF = dplyr::select(RM_SF, TripID, type, Date, MonitorReport, TimeChecked, Result)
RM_FH = dplyr::select(RM_FH, TripID, type, Date, MonitorReport, TimeChecked, Result)
RM_FF_BC = dplyr::select(RM_FF_BC, TripID, type, Date, MonitorReport, Time, Result) %>%
  mutate(Time = as_hms(sapply(strsplit(as.character(Time)," "), tail,1))) %>% 
  rename(TimeChecked = Time) 

# makes sure classes match
FH$Date = as.POSIXct(FH$Date,  format = "%d/%m/%Y")
SF$Date = as.POSIXct(SF$Date,  format = "%d/%m/%Y")
FF_BC$Date = as.POSIXct(as.character(FF_BC$Date),  format = "%Y-%m-%d") #is UTC, needs to be EST to combine
RM_FF_BC$Date = as.character(format(RM_FF_BC$Date, format = "%d/%m/%Y")) # reformat
trip_sum$Date = as.POSIXct(trip_sum$Date,  format = "%m/%d/%Y")
  
# combine all trip reports (year is not relevant for this effort estimation)
# & combine all RM reports
#trips = bind_rows(trip_sum, SF) 
trips = bind_rows(FH, SF, FF_BC) 
RM = bind_rows(RM_FH, RM_FF_BC, RM_SF)
RM$Date = as.POSIXct(RM$Date,  format = "%d/%m/%Y")

# filter to only the last trip in the data (most up to date report)
trips = group_by(trips, TripID) %>%
 mutate(lastSH = ifelse(SH == max(SH),"yes","no"),
         lastEH = ifelse(EH == max(EH),"yes","no")) %>%
  filter(lastSH %in% "yes" & lastEH %in% "yes") %>%
  dplyr::select(-lastSH, -lastEH) 


RM = group_by(RM, TripID) %>%
  mutate(lastR = ifelse(MonitorReport == max(MonitorReport),"yes","no")) %>%
  filter(lastR %in% "yes") %>%
  dplyr::select(-lastR, -MonitorReport) %>%
  distinct() %>% ungroup()  
  
# add month, day of the week, and hour columns
trips = trips %>% 
  mutate(mo = month(Date),
         yr = year(Date),
         d = wday(Date, label = TRUE, abbr = TRUE),
         hr = hour(EHLandingTime),
         type = str_to_title(type))
RM = RM %>% 
  mutate(mo = month(Date),
         yr = year(Date),
         d = wday(Date, label = TRUE, abbr = TRUE),
         hr = hour(TimeChecked),
         hr = ifelse(type %in% "charter" & hr < 9, hr + 12, hr),# incorrect time (LOTS of these)
         type = str_to_title(type)) %>%
  filter(!is.na(type)) # remove rows lacking data

# summarize trips by month
trips = filter(trips, !TripID %in% 1191070) #remove test trip
trip_sum_byMonth = trips %>% 
  distinct() %>% 
  group_by(mo, yr, type) %>% 
  dplyr::summarise(n=n(), .groups = 'drop') %>%
  mutate(month = mo, 
         month = replace(month, month %in% 1, "Jan."),
         month = replace(month, month %in% 2, "Feb."),
         month = replace(month, month %in% 3, "Mar."),
         month = replace(month, month %in% 4, "Apr."),
         month = replace(month, month %in% 5, "May."),
         month = replace(month, month %in% 6, "Jun."),
         month = replace(month, month %in% 7, "Jul."),
         month = replace(month, month %in% 8, "Aug."),
         month = replace(month, month %in% 9, "Sep."),
         month = replace(month, month %in% 10, "Oct."),
         month = replace(month, month %in% 11, "Nov."),
         month = replace(month, month %in% 12, "Dec."))

# summarize trips by day of the week
trip_sum_byDay = trips %>% 
  distinct() %>% 
  group_by(type, d) %>% 
  dplyr::summarise(n=n(), .groups = 'drop')

# summarize trips by landing time
trip_sum_byHour = trips %>% 
  distinct() %>% 
  group_by(type, hr) %>% 
  dplyr::summarise(n=n(), .groups = 'drop')

# summarize RM spot check time
RM_sum_byHour = RM %>% 
  mutate(Result = toupper(Result)) %>%
  filter(Result %in% c("MONITORED", "MONITORED (ON PAPER)")) %>%
  distinct() %>% 
  group_by(type, hr) %>% 
  dplyr::summarise(n=n(), .groups = 'drop')

# summarize by zipcode
trip_sum_byZip = trips %>% 
  distinct() %>% 
  group_by(type, EHZip) %>% 
  dplyr::summarise(n=n(), .groups = 'drop')

# load zips
## https://data.imap.maryland.gov/datasets/maryland::maryland-census-data-zip-code-tabulation-areas-zctas/about
source("Library/CloudStorage/OneDrive-SharedLibraries-OysterRecoveryPartnership,Inc/ORP - Operations/Sustainable Fisheries/E-Reporting/Pilot Projects/Roving Monitors/code/importRegions.R")
zips = shapefile("Library/CloudStorage/OneDrive-SharedLibraries-OysterRecoveryPartnership,Inc/ORP - Operations/GIS/Background Data/County Shapefiles/Maryland_Political_Boundaries__ZIP_Codes__5_Digit.shp")  
zips_df = broom::tidy(zips, region = "ZIPCODE1") 
zips_df = filter(zips_df, id %in% zip_region_list$Zip) %>% 
  mutate(id = as.numeric(id))
zips_df = left_join(zips_df, trip_sum_byZip, by = c("id"="EHZip"))

# gears
trip_sum_SF_Gear = trips %>% 
  filter(type %in% "Shellfish") %>% 
  group_by(EHZip, Gear) %>% 
  dplyr::summarise(n=n(), .groups = 'drop') %>% 
  filter(!is.na(Gear))

zips_df2 = broom::tidy(zips, region = "ZIPCODE1") 
zips_df2 = filter(zips_df2, id %in% zip_region_list$Zip) %>% 
  mutate(id = as.numeric(id))
zips_df2 = left_join(zips_df2, trip_sum_SF_Gear, by = c("id"="EHZip"))

#-----------#
```

## Which months should a Roving Monitor be monitoring each fishery
If granted the NOAA FIS RFP, funding would start in spring 2023 and would encompass 12 months. Here is an outline of when the fishery opens/closes. A visual of this can be seen in confluence [here](https://oysterrecoverypartnership.atlassian.net/wiki/spaces/EREPORTING/pages/1819213825/Fisheries+Dates).    

*  Shellfish:
     +  Oysters are open 10/1 - 3/31 except weekends. Different gears have different opening dates, e.g. dredge opens 11/1.
     +  Soft Shell Clams are open year round except Sunday
     +  Razor Clams are open year round except Sunday. The bulk of harvest correlates with blue crab. 
     +  Hard Shell Clams are open 9/15 - 5/31 except Sunday but are unlikely. Fishery is functionally extinct in bay.
*  Charter: see full species opening dates in list in the [confluence link](https://oysterrecoverypartnership.atlassian.net/wiki/spaces/EREPORTING/pages/1819213825/Fisheries+Dates)
     +  Striped Bass are open for trophy season in early May, then open 6/1 - 12/31. It is likely there will be a clouse in July or August. 
*  Finfish: see full species open dates in list in the [confluence link](https://oysterrecoverypartnership.atlassian.net/wiki/spaces/EREPORTING/pages/1819213825/Fisheries+Dates)
     +  Yellow Perch are open 12/1 - 3/31
     +  Striped Bass openings are gear dependent, see the [confluence link](https://oysterrecoverypartnership.atlassian.net/wiki/spaces/EREPORTING/pages/1819213825/Fisheries+Dates)
*  Blue Crab
     +  Dates differ for hard, soft, and peelers but generally encompasses 4/1 - 12/15

```{r, echo=FALSE}
# plot for month summary
ggplot() + 
  geom_bar(data = trip_sum_byMonth, aes(reorder(month, mo), n, fill = type), 
           stat = "identity" , position = "stack") + 
  labs(x = "Month", y = "Number of Trips", fill = "Fishery", title = "Trip Frequency by Month") + 
  theme_bw() +
  theme(text = element_text(size = 15),
        legend.position = "bottom") 
```

```{r, echo = FALSE}
# plot for day summary
ggplot() + 
  geom_bar(data = trip_sum_byDay, aes(x=d, y=n, fill = type), 
           stat = "identity" , position = "stack") + 
  labs(x = "Day of the Week", y = "Number of Trips", fill = "Fishery", title = "Trip Frequency by Day") + 
  theme_bw() +
  theme(text = element_text(size = 15),
        legend.position = "bottom") 
```

## How to decide on time blocks  
Here is the time block divisions that we have used so far:    

*  For finfish and bluecrab we had six hour time blocks. 
      + 7 am - 1 pm 
      + 11 am - 5 pm 
      + 3 pm - 9 pm 
*  For shellfish, roving monitors work eight days a month in six hour time blocks. Keep in mind that under the current managment, there is no fishing on weekends. Here is the landing time guidance in the permit: Oysters by 2:30 p.m. when using shaft tong, patent tong, dredge boat, diving apparatus, or power
dredge; Oysters at least 1/2 hour before sunset when using a dredge boat propelled by means of an auxiliary
yawl boat; and Clams at least 1/2 hour before sunset.  See an example schedule used for March 2022  [here](https://oysterrecoverypartnership.atlassian.net/wiki/spaces/EREPORTING/pages/1832714241/March+2022). 
    +  8 am - 2 pm
    +  9 am - 3 pm
    +  12 pm - 6 pm
    +  Carrie has requested that some time in the future we also have roving monitors at dealers, this may or may not be included in this effort but keep it in mind.
*  For charter, roving monitors worked. There is no time restriction for landing times and some trips could even occur late into the evening or overnight. Keep in mind that under the current management we have seen striped bass closures in July or August. Fishing trips still occur but at a decreased level. See an example schedule for July 2021 [here](https://oysterrecoverypartnership.atlassian.net/wiki/spaces/EREPORTING/pages/1633484811/July+2021).
     +  9 am - 1 pm
     +  1 pm - 3 pm
     +  2 pm - 6 pm
     +  4 pm - 8 pm (this was usually weighted less than other shifts)
*  On board observers do not have time blocks.   

```{r, echo=FALSE}
# plot for hour summary
ggplot() + 
  geom_bar(data = trip_sum_byHour, aes(hr, n, fill = type), 
           stat = "identity" , position = "stack") + 
  labs(x = "Landing Hour", y = "Number of Trips", fill = "Fishery", title = "Frequency of Trip Landings") + 
  theme_bw() +
  theme(text = element_text(size = 15),
        legend.position = "bottom") 
# tables
```
This plot was made using End Hail landing time. Watermen are notoriously poor reporters for their landing time and at this time we can't calculate how biased these numbers are. To account for this, the plot below is the time a successful spot check occurred. Of course these numbers are also limited since they are within our defined time blocks. Additionally, there appear to be errors (e.g 2 am instead of 2 pm) in these data. 

```{r, echo=FALSE}
ggplot() + 
  geom_bar(data = RM_sum_byHour, aes(hr, n, fill = type), 
           stat = "identity" , position = "stack") + 
  labs(x = "Landing Hour", y = "Number of Trips", fill = "Fishery", title = "Frequency of Spot Checks for Each Hour") + 
  theme_bw() +
  theme(text = element_text(size = 15),
        legend.position = "bottom") 
```

## How to break up the regions  
Data are summarize by zip code to help inform where to divide the regions for effort. Currently the plan is to have six roving monitors, with six regions. There will additionally be two onboard observers. For the onboard observers the regions would be divided by the bay bridge so an analysis for this division is not needed. It should be noted that there will be out of state zip codes that occur in the data form Virginia and Delaware. Roving monitors will not meet those that land out of state; however, if they are incorrectly listing their home address instead of their landing site it should be corrected if possible. Zip code errors do occurr in the earlier data before the address verification was added in FACTS. 

```{r, echo=FALSE, fig.width=8, fig.height=12}
# plot for zip code summary
ggplot() + 
  geom_polygon(data = zips_df, aes(y = lat, x = long,  fill = log(n), group = group)) + 
  labs(x = "Longitude", y = "Latitude", fill = "Log Transformed Number of Trips", title = "Number of Trips in Each Zip Code") + 
  theme_bw() +
  theme(text = element_text(size = 20),
        legend.position = "bottom") +
  scale_fill_viridis(option = "C")
```
     
Keep in mind, these regions may need to shift seasonally to accommidate trips. Consider the monthly graph above, and this zip code plot may need to be recreated by season.   
  
Different gears are additionally permitted differently depending on tributary and may need to be considered in each region.  

```{r, echo = FALSE, fig.width=8, fig.height=12}
ggplot() + 
  geom_polygon(data = zips_df, aes(y = lat, x = long,  group = group), fill="grey") + 
  geom_polygon(data = zips_df2, aes(y = lat, x = long,  fill = n, group = group)) + 
  labs(x = "Longitude", y = "Latitude", fill = "Number of Shellfish Trips by Gear", 
       title = "Number of Shellfish Trips by Gear and Zip Code") + 
  facet_wrap(~Gear) +
  theme_bw() +
  theme(text = element_text(size = 20),
        legend.position = "bottom") +
  scale_fill_viridis(option = "C")
```


## Past reports
Please see these past reports for more guideance.   

*  [2013 Blue Crab Pilot](https://oysterrecovery.sharepoint.com/:b:/g/ES5uAREyU2ROj4RnxtprqhMBz2Usk-_8wm1GTtkAN3-S9A?e=1fwc4g). See appendix [here](https://oysterrecovery.sharepoint.com/:b:/g/ESwVPyAkruNFoL3A3l3IUoQBUyLiOxF3PcD09NW9wBo77w?e=9xiD6i). 
*  [2014 Blue Crab Pilot](https://oysterrecovery.sharepoint.com/:b:/g/EQ4uaGE2_gtNqXsR18myXXUB0aqLJmePPN1aFWZb5BOSyA?e=fhC3j3).
*  Finfish (Links needed for 2015 striped bass and 2016 yellow perch)
*  [2019 Roving Monitor Improvement Pilot](https://oysterrecovery.sharepoint.com/:w:/g/EcGkdQRPimdLj2thgXisEVIB0YMo_fSzsYJWij32MLmabA?e=z4Sy91)
*  [2020 Charter Pilot](https://oysterrecovery.sharepoint.com/:w:/g/EUYIihNppzBFhQwSY7MJM_YBQiEQ5NDaImAdhhNY74n6TA?e=2cCLmq)
*  2022 Charter final report (link needed once finshed)
*  2022 Shellfish (link needed once finshed)

